{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder with single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X,size):\n",
    "    return X[np.random.choice(len(X), size, replace = False)]\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size = 10, epoch=250, learning_rate=0.001):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        x = tf.placeholder(tf.float32,[None, input_dim])    # N_samples x N_features\n",
    "        \n",
    "        with tf.name_scope('encoder'):\n",
    "            weights = tf.Variable(tf.random_normal([input_dim, hidden_dim]), dtype = tf.float32, name='weights') # N_features x N_hidden\n",
    "            bias = tf.Variable(tf.zeros([1,hidden_dim]), dtype = tf.float32, name = 'bias') # 1 x N_hidden\n",
    "            encoded = tf.nn.tanh(x @ weights + bias) # N_samples x N_hidden\n",
    "        with tf.name_scope('decoder'):\n",
    "            weights = tf.Variable(tf.random_normal([ hidden_dim, input_dim]), dtype = tf.float32, name='weights') # N_hiddenx N_features\n",
    "            bias = tf.Variable(tf.zeros([1,input_dim]), dtype = tf.float32, name = 'bias')  # 1 x N_features\n",
    "            decoded = (encoded @ weights + bias) # N_samples x N_features\n",
    "        \n",
    "        self.x = x\n",
    "        self.encoded = encoded\n",
    "        self.decoded = decoded\n",
    "            \n",
    "        self.cost = tf.sqrt(tf.reduce_mean(tf.square(self.x-self.decoded)))\n",
    "        self.train_op = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        # Gradient descent is slowest: Here are other choices -\n",
    "        # tf.train.AdagradOptimizer, tf.train.AdagradDAOptimizer,\n",
    "        # tf.train.MomentumOptimizer, tf.train.AdamOptimizer, tf.train.FtrlOptimizer\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def train(self, data):\n",
    "        num_samples = len(data)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(self.epoch):\n",
    "                for j in range(500):\n",
    "                    batch_data = get_batch(data, self.batch_size)\n",
    "                    loss, _ = sess.run([self.cost, self.train_op], feed_dict={self.x : batch_data})\n",
    "                if i % 10 ==0: \n",
    "                    print('epoch {} : loss = {}' .format(i,loss))\n",
    "                    self.saver.save(sess,'./model.ckpt')\n",
    "            self.saver.save(sess,'./model.ckpt')\n",
    "        \n",
    "    def test(self, data):\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess,'./model.ckpt')\n",
    "            hidden, reconstructed = sess.run([self.encoded, self.decoded], feed_dict = {self.x : data})\n",
    "            print('Input : ', data)\n",
    "            print('Compressed : ', hidden)\n",
    "            print('Reconstructed : ', reconstructed)\n",
    "        return reconstructed\n",
    "                    \n",
    "                    \n",
    "                               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2\n",
    "data = datasets.load_iris().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "epoch 0 : loss = 2.808366298675537\n",
      "epoch 10 : loss = 0.3598375618457794\n",
      "epoch 20 : loss = 0.29263854026794434\n",
      "epoch 30 : loss = 0.22453029453754425\n",
      "epoch 40 : loss = 0.1625186651945114\n",
      "epoch 50 : loss = 0.24175681173801422\n",
      "epoch 60 : loss = 0.15716493129730225\n",
      "epoch 70 : loss = 0.14195756614208221\n",
      "epoch 80 : loss = 0.21882644295692444\n",
      "epoch 90 : loss = 0.12144515663385391\n",
      "epoch 100 : loss = 0.13053126633167267\n",
      "epoch 110 : loss = 0.16964773833751678\n",
      "epoch 120 : loss = 0.12869258224964142\n",
      "epoch 130 : loss = 0.21167388558387756\n",
      "epoch 140 : loss = 0.1335882693529129\n",
      "epoch 150 : loss = 0.17544421553611755\n",
      "epoch 160 : loss = 0.21398349106311798\n",
      "epoch 170 : loss = 0.19584070146083832\n",
      "epoch 180 : loss = 0.1731225550174713\n",
      "epoch 190 : loss = 0.2146349996328354\n",
      "epoch 200 : loss = 0.18619698286056519\n",
      "epoch 210 : loss = 0.1584845334291458\n",
      "epoch 220 : loss = 0.17554248869419098\n",
      "epoch 230 : loss = 0.1939953714609146\n",
      "epoch 240 : loss = 0.15807777643203735\n",
      "WARNING:tensorflow:From G:\\Anaconda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Input :  [[8, 4, 6, 2]]\n",
      "Compressed :  [[0.6250639  0.30424637]]\n",
      "Reconstructed :  [[7.7075195 3.8365688 5.814247  2.0576754]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.7075195, 3.8365688, 5.814247 , 2.0576754]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(data[0])\n",
    "ae = Autoencoder(input_dim, hidden_dim)\n",
    "ae.train(data)\n",
    "ae.test([[8, 4, 6, 2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
